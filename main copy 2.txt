import tkinter as tk
from tkinter import messagebox
from tkinter import ttk
from PIL import Image, ImageTk
import pyttsx3
import speech_recognition as sr
import os
import json
import cv2
import face_recognition
import time
from features.nlp import NLPSystem
from services.spotify_integration import SpotifyIntegration
from services.weather_service import WeatherService
from services.calendar_service import CalendarService
from ui.JaicatUI import JaicatUI
from services.finance import FinanceService
from services.job_search import JobSearchService
from services.youtube_analysis import YouTubeAnalysis
from services.travel_recommendations import TravelRecommendations
from services.usb_cam import USBCam
from services.project_management import ProjectManagement
from services.phone_cam import PhoneCamera
from services.swann_cctv import SwannCCTV
from services.ip_cam import IPCamera
from services.food import FoodService
from services.file_analysis import FileAnalysisService
import tkinter as tk
from tkinter import messagebox
from tkinter import ttk
from services.business_management import BusinessManagementService
from services.project_management import ProjectManagement


from utils.file_handling import read_file, write_to_file, file_exists, get_file_extension, list_files_in_directory
from network.socket_utils import create_socket, listen_for_connections, accept_connection, send_data, receive_data, close_socket
from machine_learning.tensorflow_utils import load_model, make_prediction, evaluate_model, preprocess_data



from lib.nlp.translation import TranslationService
from lib.nlp.spacy_utils import SpacyUtils
from lib.nlp.medical import MedicalNLP
from lib.nlp.fitness import FitnessNLP
from lib.nlp.engineering import EngineeringNLP
from lib.nlp.crime import CrimeAnalyzer
from lib.nlg.Social_media_post import SocialMediaPostGenerator
from computer_vision.home_surveillance import HomeSurveillance
from computer_vision.contact_recognition import ContactRecognition
from computer_vision.car_model import CarModel
from command.Commands import CommandProcessor
from services.bluetooth_service import BluetoothService



class Jaicat:
    def __init__(self):
        self.window = tk.Tk()
        self.window.title("Jaicat AI Assistant")
        print("Initializing the Jaicat AI assistant...")

        # Initialize text-to-speech engine
        self.engine = pyttsx3.init()
        self.engine.setProperty('rate', 150)
        self.engine.setProperty('volume', 1.0)

        # Initialize speech recognition
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()

        self.weather_service = WeatherService()  # Initialize Weather Service
        self.calendar_service = CalendarService()  # Initialize Calendar Service
        # Track current user and face recognition state
        self.current_user = None
        self.face_recognized = False
        self.enrollment_pictures_path = 'C:\\Users\\josh_\\Desktop\\jaicat_project\\enrollment_pictures\\'
        self.enrollment_json_path = 'C:\\Users\\josh_\\Desktop\\jaicat_project\\enrollment_json\\'
       

        self.create_widgets()

        # Initialize NLP system
        self.nlp_system = NLPSystem()

        # Initialize GUI
        print("Setting up the GUI...")
        self.window = tk.Tk()
        self.window.title("Jaicat AI Assistant")
        self.window.geometry("1200x800")  # Set window size
        self.window.configure(bg="#2C3E50")  # Change background color

        self.create_widgets()

        self.finance_service = FinanceService()

        self.finance_service = FinanceService()

        self.job_search_service = JobSearchService()

        self.travel_recommendations_service = TravelRecommendations()

        self.usb_cam_service = USBCam()

        self.project_management_service = ProjectManagement()

        self.phone_camera_service = PhoneCamera()

        self.swann_cctv_service = SwannCCTV(api_key=swann_api_key, base_url=swann_base_url)

        self.ip_camera_service = IPCamera(camera_url=camera_url)

        self.food_service = FoodService(api_key=api_keys)

        self.file_analysis_service = FileAnalysisService()

        self.translation_service = TranslationService()

        self.spacy_utils = SpacyUtils()
    
        self.medical_nlp = MedicalNLP()

        self.fitness_nlp = FitnessNLP()

        self.engineering_nlp = EngineeringNLP()

        self.crime_analyzer = CrimeAnalyzer(data_path='path_to_your_crime_data.csv')

        self.social_media_post_generator = SocialMediaPostGenerator()
        
        self.surveillance_system = HomeSurveillance()

        self.contact_recognition_system = ContactRecognition()

        self.car_model_system = CarModel("path/to/yolov3.weights", "computer_vision/yolov7.cfg", "computer_vision\coco.names")

        self.command_processor = CommandProcessor()

        self.bluetooth_service = BluetoothService()
        
        self.business_management_service = BusinessManagementService()

    def recognize_face(self):
        """Perform face recognition and load user data."""
        if self.face_recognized:
            print("Face already recognized. Skipping face recognition...")
            return
        
        print("Recognizing face...")
        temp_img = face_recognition.load_image_file('temp.png')
        face_encodings = face_recognition.face_encodings(temp_img)
        if not face_encodings:
            self.speak("No face detected in the captured image. Please try again.")
            return
        
        temp_face_encoding = face_encodings[0]

        # Load known faces for comparison
        self.known_faces = []
        self.known_face_names = []
        for file in os.listdir(self.enrollment_pictures_path):
            if file.endswith(".png"):
                img = face_recognition.load_image_file(os.path.join(self.enrollment_pictures_path, file))
                face_encodings = face_recognition.face_encodings(img)
                if face_encodings:
                    self.known_faces.append(face_encodings[0])
                    self.known_face_names.append(file.split('.')[0])

        # Compare with known faces
        matches = face_recognition.compare_faces(self.known_faces, temp_face_encoding)
        if True in matches:
            first_match_index = matches.index(True)
            name = self.known_face_names[first_match_index]
            print(f"Face recognized as {name}.")
            self.confirm_name(name)
        else:
            print("Face not recognized.")
            self.enroll_voice()
            self.speak("You are not recognized. Please enroll your voice to continue.")

    def confirm_name(self, matched_name):
        """Confirm the recognized user's name."""
        print(f"Asking for name confirmation: {matched_name}")
        self.speak(f"Is your name {matched_name}?")
        with self.microphone as source:
            audio = self.recognizer.record(source, duration=5)
        try:
            response = self.recognizer.recognize_google(audio)
            print(f"User response: {response}")
            if "yes" in response.lower():
                self.speak(f"Hello {matched_name}, I'm Jaicat. You can now ask me questions.")
                self.current_user = matched_name
                self.load_user_data(matched_name)
            else:
                print("Name confirmation failed. Starting enrollment...")
                self.enroll_voice()
        except sr.UnknownValueError:
            print("Speech recognition failed. Trying again...")
            self.speak("Sorry, I didn't catch that. Please try again.")
            self.confirm_name(matched_name)

    def enroll_voice(self):
        """Enroll the user by capturing their voice and name."""
        print("Starting voice enrollment...")
        self.speak("Please say your name after the tone.")
        with self.microphone as source:
            audio = self.recognizer.listen(source)
        try:
            name = self.recognizer.recognize_google(audio)
            print(f"Name heard: {name}")
            self.speak(f"Thank you {name}! Enrollment complete.")
            face_image_path = 'temp.png'

            # Save user data
            user_data = {
                "name": name,
                "admin_status": False,
                "accessible_features": ["nlp", "text_classification", "code_generation"]
            }
            json_file_path = os.path.join(self.enrollment_json_path, f"{name}.json")
            save_encrypted_data(user_data, json_file_path)

            # Save the face image
            if os.path.exists(face_image_path):
                os.rename(face_image_path, self.enrollment_pictures_path + f"{name}.png")

            self.face_recognized = True
            self.current_user = name
            self.process_user_commands(name)
        except sr.UnknownValueError:
            print("Name recognition failed. Retrying...")
            self.speak("Sorry, I didn't catch that. Please try again.")
            self.enroll_voice()
            
    def load_user_data(self, name):
            """Load user data from the encrypted JSON file."""
            json_file_path = os.path.join(self.enrollment_json_path, f"{name}.json")
            if os.path.exists(json_file_path):
                user_data = load_encrypted_data(json_file_path)
                self.speak(f"Welcome back, {user_data['name']}!")
                self.current_user = name
            else:
                self.speak("No user data found. Starting enrollment...")
                self.enroll_voice()

    def run(self):
        """Start the Jaicat assistant."""
        print("Starting the assistant...")
        self.speak("Initializing the Jaicat AI assistant...")
        self.window.after(1000, self.check_face)
        self.window.mainloop()

    def check_face(self):
        """Check for user's face using the webcam."""
        print("Starting face check...")
        cap = cv2.VideoCapture(0)
        self.speak("Checking face...")
        while True:
            ret, frame = cap.read()
            if not ret:
                self.speak("Error: Unable to capture frame from camera.")
                break
            cv2.imwrite('temp.png', frame)
            self.speak("Face picture taken!")
            break
        cap.release()
        cv2.destroyAllWindows()

        self.recognize_face()


    def create_widgets(self):
        """Set up the UI components like buttons, labels, input boxes, etc."""
        
        # Frame to contain all widgets
        main_frame = tk.Frame(self.window, bg="#2C3E50")
        main_frame.pack(fill="both", expand=True)

        # Label to show the face image
        self.face_image_label = tk.Label(main_frame)
        self.face_image_label.grid(row=0, column=0, padx=10, pady=10, columnspan=2)

        # Button to play a song via Spotify
        self.play_button = tk.Button(main_frame, text="Play Music", command=self.play_song, font=("Arial", 12), bg="#3498db", fg="white")
        self.play_button.grid(row=1, column=0, padx=10, pady=10)

        # Calendar Widget
        self.calendar_label = tk.Label(main_frame, text="Calendar", font=("Arial", 14), bg="#2C3E50", fg="white")
        self.calendar_label.grid(row=2, column=0, padx=10, pady=10)
        self.calendar = tk.Label(main_frame, text=self.calendar_service.get_current_date(), font=("Arial", 14), bg="#1ABC9C", fg="white")
        self.calendar.grid(row=3, column=0, padx=10, pady=10)

        # Weather Label
        self.weather_label = tk.Label(main_frame, text="Weather", font=("Arial", 14), bg="#2C3E50", fg="white")
        self.weather_label.grid(row=2, column=1, padx=10, pady=10)
        self.weather = tk.Label(main_frame, text=self.weather_service.get_weather(42.3478, -71.0466), font=("Arial", 14), bg="#1ABC9C", fg="white")
        self.weather.grid(row=3, column=1, padx=10, pady=10)

        # Circular Button for user input
        self.input_button = tk.Button(main_frame, text="Text Input", command=self.show_input_box, font=("Arial", 12), bg="#E74C3C", fg="white")
        self.input_button.grid(row=4, column=0, padx=10, pady=10)

        # Hidden text input box
        self.text_input = tk.Entry(main_frame, font=("Arial", 14))
        self.text_input.grid(row=5, column=0, padx=10, pady=10, columnspan=2)
        self.text_input.grid_remove()

        # Status Bar
        self.status_bar = tk.Label(self.window, text="Ready", bd=1, relief=tk.SUNKEN, anchor=tk.W, font=("Arial", 12))
        self.status_bar.pack(side=tk.BOTTOM, fill=tk.X)

    def show_input_box(self):
        """Show the hidden input box when the button is clicked."""
        self.text_input.grid()
    


    def example_spacy_usage():
        spacy_utils = SpacyUtils()
        text = "Apple is looking at buying U.K. startup for $1 billion"
        analysis = spacy_utils.analyze_text(text)
        print("Tokens:", analysis['tokens'])
        print("Entities:", analysis['entities'])
        print("POS Tags:", analysis['pos_tags'])

    def example_medical_usage():
        medical_nlp = MedicalNLP()
        text = "The patient has a headache and nausea, which are symptoms of the flu."
        analysis = medical_nlp.analyze_medical_text(text)
        print("Entities:", analysis['entities'])
        print("Symptom Classification:", analysis['symptom_classification'])
    
    def example_usage():
    # Example: Read a file
        content = read_file('path/to/your/file.txt')
        print(content)

        # Example: Write to a file
        result = write_to_file('path/to/your/output.txt', 'This is a test content.')
        print(result)

        # Example: Check if a file exists
        exists = file_exists('path/to/your/file.txt')
        print("File exists:", exists)

        # Example: Get file extension
        extension = get_file_extension('path/to/your/file.txt')
        print("File extension:", extension)

        # Example: List files in a directory
        files = list_files_in_directory('path/to/your/directory')
        print("Files in directory:", files)
    def example_server():
    # Create a socket
        server_socket = create_socket(port=8080)

        # Listen for incoming connections
        listen_for_connections(server_socket)

        # Accept a connection
        client_socket, address = accept_connection(server_socket)

        # Send and receive data
        send_data(client_socket, "Hello, client!")
        data = receive_data(client_socket)

        # Close the sockets
        close_socket(client_socket)
        close_socket(server_socket)
    
    def example_usage():
        # Load a pre-trained model
        model_path = "path/to/your/model.h5"
        model = load_model(model_path)

        # Preprocess input data
        input_data = ...  # Load your input data here
        processed_data = preprocess_data(input_data)

        # Make a prediction
        prediction = make_prediction(model, processed_data)

        # Evaluate the model
        test_data = ...  # Load your test data here
        test_labels = ...  # Load your test labels here
        evaluate_model(model, test_data, test_labels)

    def example_translation_usage():
        translator = TranslationService()
        text = "Hello, how are you?"
        translated_text = translator.translate_text(text, dest_language='es')  # Translate to Spanish
        print(f"Translated text: {translated_text}")

    def display_calendar_events(self):
        events = self.calendar_service.get_upcoming_events()
        if events:
            event_text = "\n".join(events)
            self.display_response(f"Upcoming events:\n{event_text}")
        else:
            self.display_response("No upcoming events.")
    def control_bluetooth_device(self, device_name):
        response = self.bluetooth_service.connect_to_device(device_name)
        self.display_response(response)

    def check_stock_price(self, stock_name):
        stock_price = self.finance_service.get_stock_price(stock_name)
        if stock_price:
            self.display_response(f"The current price of {stock_name} is {stock_price}")
        else:
            self.display_response(f"Couldn't fetch the stock price for {stock_name}.")

    def play_song(self):
        self.display_response("Playing music via Spotify...")
        response = SpotifyIntegration().play_song("Imagine")
        self.display_response(response)

    def display_response(self, message):
        """Display a response in the status bar or as a message box."""
        self.status_bar.config(text=message)
        messagebox.showinfo("Jaicat", message)

    def change_user_face(self, mood="neutral"):
        """Change the face image based on mood."""
        if mood == "happy":
            face_image = Image.open("face_happy.png")
        elif mood == "flirty":
            face_image = Image.open("face_flirty.png")
        elif mood == "sad":
            face_image = Image.open("face_sad.png")
        else:
            face_image = Image.open("face_neutral.png")

        self.face_image_tk = ImageTk.PhotoImage(face_image)
        self.face_image_label.config(image=self.face_image_tk)
        self.face_image_label.image = self.face_image_tk

    def set_mood(self, mood):
        """Set the current mood and update behavior."""
        self.current_mood = mood
        self.update_mood_behavior()

    def update_mood_behavior(self):
        """Update the face and speech based on the current mood."""
        if self.current_mood == "happy":
            self.change_user_face(mood="happy")
            self.speak("I'm feeling great today!")
        elif self.current_mood == "flirty":
            self.change_user_face(mood="flirty")
            self.speak("Hello there, looking good!")
        elif self.current_mood == "sad":
            self.change_user_face(mood="sad")
            self.speak("I'm feeling a bit down today.")
        else:
            self.change_user_face(mood="neutral")
            self.speak("I'm here to assist you.")

    def recognize_face(self):
        """Perform face recognition."""
        # Implement face recognition logic
        self.face_recognized = True
        self.current_user = "Jay"
        if self.current_user == "Jay":
            self.set_mood("flirty")  # Set flirty mood for Jay
        else:
            self.set_mood("neutral")  # Default mood for others

    def speak(self, text):
        """Speak with different styles based on the current mood."""
        if self.current_mood == "happy":
            text = "ðŸ˜Š " + text
        elif self.current_mood == "flirty":
            text = "ðŸ’– " + text
        elif self.current_mood == "sad":
            text = "ðŸ˜¢ " + text

        print(f"Speaking: {text}")
        self.engine.say(text)
        self.engine.runAndWait()

    def process_user_input(self, user_input):
        """Process the input using NLP and respond."""
        # Using NLP and NLU to analyze the user input
        sentiment = self.nlp_system.analyze_sentiment(user_input)
        
        # Change mood based on sentiment analysis
        if sentiment == "positive":
            self.set_mood("happy")
        elif sentiment == "negative":
            self.set_mood("sad")
        else:
            self.set_mood("neutral")
        # Generate a response using NLP
        response = self.nlp_system.process(user_input)
        self.speak(response)
    
    def analyze_youtube_video(self, video_url):
        """Analyze the YouTube video using the YouTube analysis service."""
        video_id = video_url.split("v=")[-1]  # Extract video ID from URL
        analysis_results = self.youtube_service.analyze_youtube_video(video_id)
        self.speak(f"Title: {analysis_results['title']}, Description: {analysis_results['description']}")
    
    def extract_intent(text):
    # NLU logic to identify intent from user input
        pass

    def extract_entities(text):
    # NLU logic to extract relevant entities like 'song_name', 'job_title', etc.
        pass
    
    
    def recognize_speech(self):
            """Recognize speech and return the command."""
            print("Listening for speech...")
            with self.microphone as source:
                audio = self.recognizer.listen(source)
            try:
                command = self.recognizer.recognize_google(audio)
                print(f"Recognized command: {command}")
                return command
            except sr.UnknownValueError:
                print("Speech recognition failed: UnknownValueError")
                return None
            except sr.RequestError:
                print("Speech recognition failed: RequestError")
                return None

def run(self):
        self.window.mainloop()


if __name__ == "__main__":
    assistant = Jaicat()
    assistant.run()
